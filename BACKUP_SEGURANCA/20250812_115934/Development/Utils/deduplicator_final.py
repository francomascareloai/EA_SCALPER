#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Deduplicador Final para Arquivos MQ5
Vers√£o: 3.0
Autor: Agente Organizador

Este script identifica e remove duplicatas restantes que escaparam da primeira limpeza,
incluindo padr√µes espec√≠ficos como (2), (3), vers√µes diferentes, etc.
"""

import os
import sys
import hashlib
import shutil
from pathlib import Path
from collections import defaultdict
import re
from datetime import datetime

class FinalDeduplicator:
    def __init__(self, source_dir, dry_run=True):
        self.source_dir = Path(source_dir)
        self.dry_run = dry_run
        self.duplicates_dir = self.source_dir.parent / "Duplicates_Removed_Final"
        self.log_entries = []
        
    def calculate_md5(self, file_path):
        """Calcula hash MD5 do arquivo"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            print(f"Erro ao calcular hash de {file_path}: {e}")
            return None
    
    def get_file_priority(self, file_path):
        """Determina prioridade do arquivo (menor = melhor)"""
        name = file_path.name.lower()
        score = 0
        
        # Penaliza padr√µes de duplica√ß√£o
        if re.search(r'\(\d+\)', name):  # (2), (3), etc.
            score += 100
        if re.search(r'\s+\(\d+\)', name):  # espa√ßo + (2)
            score += 50
        if re.search(r'\(\d+\)\s*\(\d+\)', name):  # (1) (2)
            score += 150
        if '@' in name:  # @canal, @grupo
            score += 30
        if re.search(r'(copy|copia|backup|bak|old|temp|test)', name):
            score += 40
        if re.search(r'(lifein|dreams|world|forex|expert|advisors)', name):
            score += 25
        if len(name.split(' ')) > 4:  # muitos espa√ßos
            score += 20
        if len(name) > 60:  # nomes muito longos
            score += 15
        
        # Favorece nomes mais limpos
        if re.match(r'^[a-zA-Z0-9_\s-]+\.mq5$', name):
            score -= 20
        if not re.search(r'[()@]', name):  # sem par√™nteses ou @
            score -= 30
        
        return score
    
    def normalize_name(self, filename):
        """Normaliza nome do arquivo para compara√ß√£o"""
        # Remove extens√£o
        name = filename.lower().replace('.mq5', '')
        
        # Remove padr√µes comuns de duplica√ß√£o
        name = re.sub(r'\s*\(\d+\)\s*', ' ', name)
        name = re.sub(r'@[a-zA-Z0-9_]+', '', name)
        name = re.sub(r'\s+', ' ', name)
        name = name.strip()
        
        return name
    
    def scan_files(self):
        """Escaneia todos os arquivos .mq5 e agrupa por hash"""
        print(f"üîç Escaneando arquivos em: {self.source_dir}")
        
        if not self.source_dir.exists():
            print(f"‚ùå Diret√≥rio n√£o encontrado: {self.source_dir}")
            return {}
        
        mq5_files = list(self.source_dir.glob("*.mq5"))
        total_files = len(mq5_files)
        
        print(f"üìÅ Encontrados {total_files} arquivos .mq5")
        
        if total_files == 0:
            print("‚ö†Ô∏è Nenhum arquivo .mq5 encontrado!")
            return {}
        
        # Agrupa arquivos por hash
        hash_groups = defaultdict(list)
        name_groups = defaultdict(list)
        
        for i, file_path in enumerate(mq5_files, 1):
            print(f"\r‚è≥ Analisando... {i}/{total_files} ({i/total_files*100:.1f}%)", end="")
            
            # Agrupa por hash MD5
            file_hash = self.calculate_md5(file_path)
            if file_hash:
                hash_groups[file_hash].append(file_path)
            
            # Agrupa por nome normalizado
            normalized_name = self.normalize_name(file_path.name)
            name_groups[normalized_name].append(file_path)
        
        print("\n‚úÖ An√°lise conclu√≠da!")
        return dict(hash_groups), dict(name_groups)
    
    def identify_duplicates(self, hash_groups, name_groups):
        """Identifica grupos de duplicatas"""
        # Duplicatas por hash (conte√∫do id√™ntico)
        hash_duplicates = {h: files for h, files in hash_groups.items() if len(files) > 1}
        
        # Duplicatas por nome (mesmo arquivo, nomes diferentes)
        name_duplicates = {n: files for n, files in name_groups.items() if len(files) > 1}
        
        # Combina ambos os tipos
        all_duplicates = {}
        
        # Adiciona duplicatas por hash
        for hash_key, files in hash_duplicates.items():
            all_duplicates[f"hash_{hash_key[:8]}"] = files
        
        # Adiciona duplicatas por nome que n√£o est√£o em hash_duplicates
        for name_key, files in name_duplicates.items():
            # Verifica se esses arquivos j√° est√£o em hash_duplicates
            already_in_hash = False
            for hash_key, hash_files in hash_duplicates.items():
                if any(f in hash_files for f in files):
                    already_in_hash = True
                    break
            
            if not already_in_hash:
                all_duplicates[f"name_{name_key}"] = files
        
        total_duplicates = sum(len(files) - 1 for files in all_duplicates.values())
        
        print("\n" + "="*50)
        print("üìä RELAT√ìRIO DE DUPLICATAS FINAIS")
        print("="*50)
        print(f"üîÑ Grupos de duplicatas por hash: {len(hash_duplicates)}")
        print(f"üìù Grupos de duplicatas por nome: {len(name_duplicates)}")
        print(f"üóëÔ∏è Total de duplicatas a remover: {total_duplicates}")
        
        return all_duplicates, total_duplicates
    
    def preview_duplicates(self, duplicate_groups, max_preview=10):
        """Mostra preview dos grupos de duplicatas"""
        if not duplicate_groups:
            print("‚úÖ Nenhuma duplicata encontrada!")
            return
        
        print(f"\nüîç PREVIEW DOS PRIMEIROS {min(max_preview, len(duplicate_groups))} GRUPOS:")
        print("-" * 60)
        
        for i, (group_key, files) in enumerate(list(duplicate_groups.items())[:max_preview], 1):
            # Ordena por prioridade
            sorted_files = sorted(files, key=self.get_file_priority)
            best_file = sorted_files[0]
            
            print(f"\nüìÅ Grupo {i} ({group_key}):")
            print(f"  ‚úÖ MANTER: {best_file.name}")
            
            for file_path in files:
                if file_path != best_file:
                    size_kb = file_path.stat().st_size / 1024
                    print(f"  ‚ùå REMOVER: {file_path.name} ({size_kb:.1f} KB)")
        
        if len(duplicate_groups) > max_preview:
            print(f"\n... e mais {len(duplicate_groups) - max_preview} grupos")
    
    def execute_deduplication(self, duplicate_groups):
        """Executa a remo√ß√£o de duplicatas"""
        if not duplicate_groups:
            return 0, 0
        
        # Cria pasta para duplicatas se n√£o existir
        if not self.dry_run:
            self.duplicates_dir.mkdir(exist_ok=True)
        
        # Inicia log
        self.log_entries = [
            "=== LOG DE REMO√á√ÉO FINAL DE DUPLICATAS ===",
            f"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"Pasta origem: {self.source_dir}",
            f"Modo: {'SIMULA√á√ÉO' if self.dry_run else 'EXECU√á√ÉO REAL'}",
            ""
        ]
        
        total_removed = 0
        space_saved = 0
        
        for group_num, (group_key, files) in enumerate(duplicate_groups.items(), 1):
            # Ordena por prioridade
            sorted_files = sorted(files, key=self.get_file_priority)
            best_file = sorted_files[0]
            files_to_remove = [f for f in files if f != best_file]
            
            print(f"\nüîÑ Processando Grupo {group_num}/{len(duplicate_groups)}")
            print(f"  Tipo: {group_key}")
            print(f"  ‚úÖ MANTENDO: {best_file.name}")
            
            self.log_entries.extend([
                f"Grupo {group_num} ({group_key}):",
                f"  MANTIDO: {best_file.name}",
                "  REMOVIDOS:"
            ])
            
            for file_to_remove in files_to_remove:
                file_size = file_to_remove.stat().st_size
                space_saved += file_size
                
                print(f"  ‚ùå REMOVENDO: {file_to_remove.name} ({file_size/1024:.1f} KB)")
                self.log_entries.append(f"    - {file_to_remove.name} ({file_size} bytes)")
                
                if not self.dry_run:
                    # Move para pasta de duplicatas
                    dest_path = self.duplicates_dir / file_to_remove.name
                    counter = 1
                    
                    # Resolve conflitos de nome
                    while dest_path.exists():
                        stem = file_to_remove.stem
                        suffix = file_to_remove.suffix
                        dest_path = self.duplicates_dir / f"{stem}_final{counter}{suffix}"
                        counter += 1
                    
                    try:
                        shutil.move(str(file_to_remove), str(dest_path))
                        total_removed += 1
                    except Exception as e:
                        print(f"  ‚ö†Ô∏è Erro ao mover {file_to_remove.name}: {e}")
                else:
                    total_removed += 1
            
            self.log_entries.append("")
        
        return total_removed, space_saved
    
    def save_log(self, total_removed, space_saved):
        """Salva log da opera√ß√£o"""
        self.log_entries.extend([
            "=== RESUMO FINAL ===",
            f"Total de arquivos removidos: {total_removed}",
            f"Espa√ßo economizado: {space_saved/1024/1024:.2f} MB",
            f"Pasta de duplicatas: {self.duplicates_dir if not self.dry_run else 'N/A (simula√ß√£o)'}"
        ])
        
        log_file = self.source_dir.parent / "deduplication_final_log.txt"
        
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.log_entries))
            print(f"\nüìù Log salvo em: {log_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar log: {e}")
    
    def run(self):
        """Executa o processo completo de deduplica√ß√£o final"""
        print("üöÄ DEDUPLICADOR FINAL MQ5")
        print("=" * 40)
        print(f"üìÇ Pasta: {self.source_dir}")
        print(f"üîß Modo: {'üü° SIMULA√á√ÉO' if self.dry_run else 'üî¥ EXECU√á√ÉO REAL'}")
        print("=" * 40)
        
        # 1. Escaneia arquivos
        hash_groups, name_groups = self.scan_files()
        if not hash_groups and not name_groups:
            return
        
        # 2. Identifica duplicatas
        duplicate_groups, total_duplicates = self.identify_duplicates(hash_groups, name_groups)
        if not duplicate_groups:
            print("\n‚úÖ Nenhuma duplicata encontrada! Pasta j√° est√° limpa.")
            return
        
        # 3. Mostra preview
        self.preview_duplicates(duplicate_groups)
        
        # 4. Executa remo√ß√£o
        print(f"\n{'üîÑ SIMULANDO' if self.dry_run else 'üóëÔ∏è EXECUTANDO'} REMO√á√ÉO FINAL...")
        print("-" * 50)
        
        total_removed, space_saved = self.execute_deduplication(duplicate_groups)
        
        # 5. Salva log
        self.save_log(total_removed, space_saved)
        
        # 6. Resultado final
        print("\n" + "="*50)
        print("üéØ RESULTADO FINAL")
        print("="*50)
        
        if self.dry_run:
            print(f"üìä Arquivos que seriam removidos: {total_duplicates}")
            print(f"üíæ Espa√ßo que seria economizado: {space_saved/1024/1024:.2f} MB")
            print("\nüí° Para executar a remo√ß√£o real, execute:")
            print("   python deduplicator_final.py --execute")
        else:
            print(f"‚úÖ Arquivos removidos com sucesso: {total_removed}")
            print(f"üíæ Espa√ßo economizado: {space_saved/1024/1024:.2f} MB")
            print(f"üìÅ Duplicatas movidas para: {self.duplicates_dir}")
        
        print("\nüéâ Limpeza final conclu√≠da!")

def main():
    """Fun√ß√£o principal"""
    # Configura√ß√µes
    source_dir = r"C:\Users\Admin\Documents\EA_SCALPER_XAUUSD\CODIGO_FONTE_LIBRARY\MQL5_Source\All_MQ5"
    
    # Verifica argumentos
    execute_mode = '--execute' in sys.argv or '-e' in sys.argv
    dry_run = not execute_mode
    
    # Executa deduplica√ß√£o final
    deduplicator = FinalDeduplicator(source_dir, dry_run=dry_run)
    deduplicator.run()
    
    # Pausa para visualiza√ß√£o
    input("\n‚è∏Ô∏è Pressione Enter para sair...")

if __name__ == "__main__":
    main()